{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(layers.Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 5\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 27, 27, 96)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 27, 27, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 13, 13, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 6, 6, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 12291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58296067 (222.38 MB)\n",
      "Trainable params: 58294851 (222.38 MB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (227, 227, 3)  # Assuming input images are of size 227x227 with 3 channels (RGB)\n",
    "num_classes = 3  # Number of classes in ImageNet dataset, change accordingly for your task\n",
    "\n",
    "\n",
    "model = alexnet(input_shape, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './Data/train',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1288 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        './Data/test',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 428s 3s/step - loss: 2.6206 - accuracy: 0.7171 - val_loss: 3.6397 - val_accuracy: 0.3478\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 443s 3s/step - loss: 0.4204 - accuracy: 0.8482 - val_loss: 0.6296 - val_accuracy: 0.7314\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 432s 3s/step - loss: 0.3415 - accuracy: 0.8766 - val_loss: 0.3270 - val_accuracy: 0.8742\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 420s 3s/step - loss: 0.2981 - accuracy: 0.8933 - val_loss: 0.2760 - val_accuracy: 0.8967\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 435s 3s/step - loss: 0.2902 - accuracy: 0.8956 - val_loss: 0.3214 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 443s 3s/step - loss: 0.2726 - accuracy: 0.9022 - val_loss: 0.2020 - val_accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 421s 3s/step - loss: 0.2508 - accuracy: 0.9075 - val_loss: 0.6293 - val_accuracy: 0.7679\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 423s 3s/step - loss: 0.2238 - accuracy: 0.9185 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 441s 3s/step - loss: 0.2345 - accuracy: 0.9164 - val_loss: 0.3290 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 441s 3s/step - loss: 0.2179 - accuracy: 0.9209 - val_loss: 0.1665 - val_accuracy: 0.9425\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 - 28s - loss: 0.1665 - accuracy: 0.9425 - 28s/epoch - 691ms/step\n",
      "\n",
      "Test accuracy: 0.9425466060638428\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 1\n",
      "True Negatives (TN): 1\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "Accuracy: 0.67\n",
      "Precision: 1.00\n",
      "Recall (Sensitivity): 1.00\n",
      "Specificity: 1.00\n",
      "False Positive Rate: 0.00\n",
      "False Negative Rate: 0.00\n"
     ]
    }
   ],
   "source": [
    "true_labels = ['covid', 'pneumonia', 'normal']  # True labels of the test set\n",
    "predicted_labels = ['covid', 'pneumonia', 'normal']  # Predicted labels of the test set\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Define class labels (if available)\n",
    "class_labels = ['covid', 'pneumonia', 'normal']  # List of class labels\n",
    "\n",
    "# Calculate TP, TN, FP, FN\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "# Calculate rates\n",
    "accuracy = (TP + TN) / np.sum(cm)  # Accuracy\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # Precision\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall (Sensitivity)\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity\n",
    "false_positive_rate = FP / (FP + TN) if (FP + TN) > 0 else 0  # False Positive Rate\n",
    "false_negative_rate = FN / (FN + TP) if (FN + TP) > 0 else 0  # False Negative Rate\n",
    "\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"False Positive Rate: {false_positive_rate:.2f}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get true labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241m.\u001b[39mclasses\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get predicted probabilities\u001b[39;00m\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(validation_generator)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Get true labels\n",
    "true_labels = validation_generator.classes\n",
    "\n",
    "# Get predicted probabilities\n",
    "predictions = model.predict(validation_generator)\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "num_classes = len(validation_generator.class_indices)\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(true_labels, predictions[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for AlexNet')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Devender\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model.save('./models/alexnet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(alexnet, './models/alexnet_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
